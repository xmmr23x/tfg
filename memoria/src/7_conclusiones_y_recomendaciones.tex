\chapter{Conclusiones y recomendaciones}
\label{ch:conclusiones}

En este último capítulo del proyecto se expondrán las conclusiones, recomendaciones y mejoras de este proyecto.

\section{Conclusiones de investigación}
\label{sec:conc_investigacion}

En cuanto a los resultados obtenidos en la investigación y dado el enfoque seleccionado en el capítulo \ref{ch:metodologia}, es necesario hacer una diferenciación entre clasificación binaria y clasificación multiclase

\subsection{Clasificación binaria}
\label{subsec:conc_bin}

Si bien es cierto que los resultados obtenidos por los clasificadores más sencillos son muy altos en cuanto a precisión, todos ellos presentan una caída apreciable en la métrica de sensibilidad mínima. Esto significa que es bastante probable un sobreajuste de los modelos y una mala generalización, lo que puede llevar a demasiados fallos en una situación real. Por otro lado, \textit{LGBMClassifier} tiene una precisión ligeramente inferior pero mayor estabilidad entre las métricas de entrenamiento y clasificación. A pesar de ser más complejo a la hora de entrenar e interpretar esta consistencia hace que sea una muy buena opción a tener en cuenta.

\subsection{Clasificación multiclase}
\label{subsec:conc_multi}

Este tipo de clasificación ha presentado varios problemas además del aumento necesario de tiempo por la configuración del conjunto de datos con todos los patrones. Por un lado, la fuerte caída de la mínima sensibilidad indica que los clasificadores tienden a priorizar las clases mayoritarias, dejando sin apenas capacidad de detección a las minoritarias. Esto provoca que, aunque la precisión o el valor-F1 puedan mantenerse razonablemente altos, el rendimiento real frente a todas las clases no es confiable.

\vspace{1em}

Por otro lado, algunos modelos como \textit{LGBMClassifier} presentan una alta varianza entre semillas. Esto implica que el conjunto de datos está fuertemente afectado por el desbalanceo, y que los modelos probados no garantizan una generalización. Además, algunos modelos presentan una sensibilidad mínima de 0, es decir, hay clases que directamente no se predicen en absoluto.

\section{Recomendaciones}
\label{sec:recomendaciones}

Las principales recomendaciones referentes a este estudio tienen su origen en las limitaciones del equipo con el que se han realizado las pruebas. A pesar de que se han obtenido muy buenos resultados tanto en entrenamiento como en test con algoritmos ligeros, es recomendable hacer pruebas con un \textit{hardware} capaz de entrenar modelos algo más lentos para hacer unas pruebas realmente concluyentes. Por ejemplo, para el modelo de máquinas de vectores de soporte, ha sido muy difícil realizar el entrenamiento ajustando una rejilla relativamente completa de parámetros, por lo que los resultados podrían llegar a mejorar. En cuanto al perceptrón multicapa sí se han podido realizar más pruebas, pero a cada ajuste de parámetros que se ha probado mejoraban considerablemente los resultados. Un equipo más potente permitiría ajustar correctamente el modelo y obtener los mejores resultados posibles.

\vspace{1em}

En cuanto al conjunto de datos, si bien es cierto que es amplio y en clasificación binaria funciona muy bien, para clasificación multiclase es insuficiente. Su principal problema se encuentra en la cantidad de clases desbalanceadas. Como podemos ver en la tabla \ref{tabla:nueva_codificacion_malware}, la cuarta clase más poblada contiene más de diez veces menos patrones que la primera. Esto implica que a la hora de entrenar, la clase más poblada influye mucho en el entrenamiento incluso aplicando varias técnicas para evitarlo. Sería recomendable hacer pruebas con distintos conjuntos de datos que dispongan de una mayor cantidad de muestras en clases minoritarias para poder hacer un entrenamiento equilibrado.
