\chapter{Código del programa}

El código completo de este proyecto se encuentra en github para su libre consulta \cite{github}

\section{Codificación de las categorías \textit{malware}}
\label{sec:codificacion}

\lstset{style=codestyle, language=Python}
\begin{lstlisting}[frame=single]
X, y        = load('bodmas/bodmas.npz')
metadata    = pd.read_csv('bodmas/bodmas_metadata.csv')
mw_category = pd.read_csv('bodmas/bodmas_malware_category.csv')

# Incluimos los valores de 'category' en metadata cuando coinciden los valoes de 'sha'
mw_category = metadata.merge(mw_category, on = 'sha', how = 'left')

# Rellenamos los huecos como software benigno
mw_category['category'] = mw_category['category'].fillna('benign')

# Eliminamos todas las columnas excepto 'category'
mw_category = mw_category['category']

# Codificamos las categorias de malware
category = {
	'benign': 0, 'trojan': 1, 'worm': 2, 'backdoor': 3,
	'downloader': 4, 'informationstealer': 5, 'dropper': 6,
	'ransomware': 7, 'rootkit': 8, 'cryptominer': 9, 'pua': 10,
	'exploit': 11, 'virus': 12, 'p2p-worm': 13, 'trojan-gamethief': 14
}

mw_category = mw_category.map(category)

y = mw_category.to_numpy()

save('bodmas/bodmas_multiclass.npz', X, y)

\end{lstlisting}

\section{Reducción de la dimensionalidad}
\label{sec:red_dim}

\lstset{style=codestyle, language=Python}
\begin{lstlisting}[frame=single]
def resampling(X, y, n_components = 5, size = 15000, u = False):
	if u:
		rus  = RandomUnderSampler(sampling_strategy = {0: size, 1: size})
		# rus  = RandomUnderSampler(sampling_strategy = 'majority')
		X, y = rus.fit_resample(X, y)

	X_train, X_test, y_train, y_test = train_test_split(
		X, y, test_size = 0.25, random_state = 1
	)

	pca     = PCA(n_components)
	X_train = pca.fit_transform(X_train)
	X_test  = pca.transform(X_test)

	return X_train, X_test, y_train, y_test
\end{lstlisting}

\newpage
\section{Pruebas para la elección del conjunto de datos}
\label{sec:select_dataset}

\lstset{style=codestyle, language=Python}
\begin{lstlisting}[frame=single]
file = {'pca_binary', 'resampling_binary', 'pca_multiclass'}
clf  = None

print('clasificador,dataset,n patrones,n caracteristicas,accuracy,tiempo')

for i in range(3):
	if i == 0: clf = DecisionTreeClassifier()
	elif i == 1: clf = RandomForestClassifier()
	else: clf = KNeighborsClassifier()

	for train_file in file:

		X_train, y_train = load('bodmas/' + train_file + '_train.npz')
		X_test, y_test = load('bodmas/' + train_file + '_test.npz')

		# Entrenar el modelo
		inicio = time.time()
		clf.fit(X_train, y_train)
		tiempo = time.time() - inicio

		# Predecir sobre el conjunto de prueba
		y_pred = clf.predict(X_test)

		# Evaluar
		accuracy = accuracy_score(y_test, y_pred)

		print(f'{i},{train_file},{X_train.shape},{accuracy:.3f},{tiempo:.3f}')

\end{lstlisting}

\newpage
\section{Control de la validación cruzada}
\label{sec:func_cv}

\lstset{style=codestyle, language=Python}
\begin{lstlisting}[frame=single]
def cv(y, crossval):
	y_ = min(pd.DataFrame(y).value_counts())

	if y_ < crossval:
		return y_

	return crossval
\end{lstlisting}

\section{Ejemplo de salida de la información}
\label{sec:info}

\lstset{style=codestyle, language=Python}
\begin{lstlisting}[frame=single]
      acc train  ms train  f1 train  acc test   ms test  f1 test
0      0.648800  0.548712       1.0  0.648133  0.530019      1.0
1      0.645200  0.558267       1.0  0.655200  0.568564      1.0
2      0.652400  0.572655       1.0  0.644667  0.563784      1.0
3      0.648578  0.566829       1.0  0.653467  0.569664      1.0
4      0.650933  0.573087       1.0  0.650933  0.573003      1.0
5      0.647289  0.562228       1.0  0.647867  0.558393      1.0
6      0.647867  0.556000       1.0  0.650267  0.572533      1.0
7      0.650667  0.570983       1.0  0.649600  0.572906      1.0
8      0.650711  0.564155       1.0  0.638800  0.551123      1.0
9      0.649911  0.563205       1.0  0.645200  0.550628      1.0
Mean   0.649236  0.563612       1.0  0.648413  0.561062      1.0
STD    0.002112  0.007797       0.0  0.004713  0.013867      0.0
\end{lstlisting}
